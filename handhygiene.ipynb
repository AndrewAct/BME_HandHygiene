{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Hand Hygigene Project \n## Target: Deploy CV2, TF, and Keras to detect hand wash process \n\n## Goal: \n1. Distinguish the current step\n2. Remind the operator if she/he doesn't follow the correct procedure"},{"metadata":{},"cell_type":"markdown","source":"## 0.0 Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2 \nimport math\nimport numpy as np \nimport matplotlib.pyplot as plt \n%matplotlib inline\nfrom kaggle_datasets import KaggleDatasets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras \nfrom keras.preprocessing import image\nfrom keras.utils import np_utils\nfrom skimage.transform import resize\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 0.1 Explore Sample Video"},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nvideoSample1 = \"../input/hand-wash-dataset/HandWashDataset/HandWashDataset/Step_1/HandWash_001_A_01_G01.mp4\"\ncap = cv2.VideoCapture(videoSample1)\nframeRate = cap.get(5)\n\nx = 1 \nwhile (cap.isOpened()):\n    frameID = cap.get(1)\n    ret, frame = cap.read()\n    if (ret != True):\n        break\n    if (frameID % math.floor(frameRate) == 0):\n        filename = \"frame%d.jpg\" % count; count += 1 \n        cv2.imwrite(filename, frame)\n        \ncap.release()\nprint(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Try it out"},{"metadata":{"trusted":true},"cell_type":"code","source":"img = plt.imread('frame0.jpg')\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 0.2 Load the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/hand-wash-dataset/HandWashDataset/HandWashDataset\"\nstep1 = \"../input/hand-wash-dataset/HandWashDataset/HandWashDataset/Step_1\"\nfor file in step1:\n    count = 0\n    cap = cv2.VideoCapture(file)\n    frameRate = cap.get(5)\n    \n    x = 1 \n    while (cap.isOpened()):\n        frameID = cap.get(1)\n        ret, frame = cap.read()\n        if (ret != True):\n            break\n        if (frameID % math.floor(frameRate) == 0):\n            filename = \"Step_1_frame%d.jpg\" % count; count += 1\n            cv2.imwrite(filename, frame)\n            \ncap.release()\nprint(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(25):\n    image = \"Step_1_frame%d.jpg\" % i\n    try:\n        img = plt.imread(image)\n        plt.imshow(img)\n    except OSError as e:\n        pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Do the same thing for Step 1 to Step 7"},{"metadata":{"trusted":true},"cell_type":"code","source":"from os import walk\nfor (dirpath, dirnames, filenames) in walk(\"../input\"):\n    print(\"Directory path: \", dirpath)\n    print(\"Folder name: \", dirnames)\n    print(\"File name: \", filenames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#(dirpath, dirnames, filenames) = walk(\"../input\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"steps = [[\"Step 1\", 0], [\"Step 2\",0],[\"Step 3\",0],[\"Step 4\",0],[\"Step 5\",0],[\"Step 6\",0],[\"Step 7\",0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nfor file in filenames:\n    video = file\n    cap = cv2.VideoCapture(video)\n    frameRate = cap.get(5)\n    x = 1 \n    while (cap.isOpened()):\n        frameID = cap.get(1)\n        ret, frame = cap.read()\n        if (ret != True):\n            break\n        if (frameID % math.floor(frameRate) == 0):\n            filename = \"frame%d.jpg\" % count; count += 1\n            cv2.imwrite(filename, frame)\n            \n    cap.release()\nprint(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### A low-efficient method to convert all video to images"},{"metadata":{},"cell_type":"markdown","source":"## 0.3 Hand Recognition\n\n*Note: the following code referred to this repo:*\n*https://github.com/BlueDi/Hand-Detection/blob/master/video_detection.py*"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}